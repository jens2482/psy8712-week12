---
title: "PSY 8712 Week 12 Project"
author: "Amanda Jensen"
output: html_document
---

### Script Settings and Resources
```{r}
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
library(tidyverse)      
library(RedditExtractoR)
library(tm)
library(qdap)
library(textstem)
library(RWeka)
```

### Data Import and Cleaning
```{r}
#import content from reddit - went with Reddit Extractor after previous web scraping project
# reddit_thread_urls <- find_thread_urls(
#   subreddit = "IOPsychology",
#   sort_by = "new",
#   period = "year")

#pull out data we want from reddit extraction
# reddit_content <- get_thread_content(reddit_thread_urls$url)

#create csv file of urls
# write_csv(reddit_thread_urls, "../data/reddit_thread_urls.csv")

#create csv file from the scraped reddit data
# write_csv(reddit_content$threads, "../data/reddit_content.csv")

#import data from csv file
data <- read_csv("../data/reddit_content.csv")

week12_tbl <- tibble(
  upvotes = data$upvotes,
  title = data$title
)
```

```{r}
io_corpus_original <- VCorpus(VectorSource(week12_tbl$title))

#create customized function to check pre-processing - used code from class lecture
compare_them <- function() {
  casenum <- sample(1:952, 1) 
  print(io_corpus_original[[casenum]]$content)
  print(io_corpus[[casenum]]$content)
}

#create customized cleaning function - this is how they did it in data camp (though I know it's not really necessary to create a function since we're only applying it to one corpus)
clean_corpus <- function(corpus) {
  corpus <- corpus %>%
    tm_map(content_transformer(replace_abbreviation)) %>% #get rid of abbreviations
    tm_map(content_transformer(replace_contraction)) %>% #replace contractions
    tm_map(removePunctuation) %>%   #remove punctuation
    tm_map(content_transformer(tolower)) %>%  #make lowercase 
    tm_map(removeWords, words = c(stopwords("en"), "io psychology", "io psych", "io", "riopsychology", "iopsychology", "iopsych")) %>%  #remove stop words
    tm_map(stripWhitespace) %>%  #strip whitespace
    tm_map(content_transformer(lemmatize_words))
  return(corpus)
}

#apply cleaning function to corpus
io_corpus <- clean_corpus(io_corpus_original)

#run function comparing cleaned corpus to original
compare_them() 
```

```{r}
#set up bigram tokenizer
bigram_tokenizer <- function(x) NGramTokenizer(x, Weka_control(min=1, max=2))

#create dtm
io_dtm <- DocumentTermMatrix(io_corpus, control = list(tokenize = bigram_tokenizer))

#view dtm
io_dtm %>%
  as.matrix %>% 
  as_tibble %>% 
  View

#remove sparse terms
io_slim_dtm <- removeSparseTerms(io_dtm, .997) #gives a N/k ratio of 2.19
```


### Visualization

### Analysis

### Publication


